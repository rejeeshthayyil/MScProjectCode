{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9235af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0eb5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\rejee\\Desktop\\Agitation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3673bd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp (ET)</th>\n",
       "      <th>agitimestamp (ET)</th>\n",
       "      <th>Location</th>\n",
       "      <th>level</th>\n",
       "      <th>Observation</th>\n",
       "      <th>Behaviour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/10/2016 21:02</td>\n",
       "      <td>12/10/2016 21:00</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/15/2016 3:22</td>\n",
       "      <td>12/15/2016 3:21</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>3</td>\n",
       "      <td>Vocal1, Withdrawn</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/15/2016 19:14</td>\n",
       "      <td>12/16/2016 2:20</td>\n",
       "      <td>Other</td>\n",
       "      <td>3</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/19/2016 1:57</td>\n",
       "      <td>12/19/2016 1:55</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/28/2016 20:36</td>\n",
       "      <td>12/28/2016 19:00</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>Vocal2, Withdrawn</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>7/29/2017 10:42</td>\n",
       "      <td>7/29/2017 10:42</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>1</td>\n",
       "      <td>Repetition;</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>08/03/2017 12:45</td>\n",
       "      <td>08/03/2017 12:44</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>1</td>\n",
       "      <td>Repetition;</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>08/04/2017 22:13</td>\n",
       "      <td>08/04/2017 22:13</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>1</td>\n",
       "      <td>Repetition;</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>08/07/2017 11:44</td>\n",
       "      <td>08/07/2017 11:44</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>1</td>\n",
       "      <td>Repetition;</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>08/08/2017 19:15</td>\n",
       "      <td>08/08/2017 19:15</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>1</td>\n",
       "      <td>Repetition;</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp (ET) agitimestamp (ET) Location  level        Observation  \\\n",
       "0    12/10/2016 21:02  12/10/2016 21:00  Kitchen      5          Withdrawn   \n",
       "1     12/15/2016 3:22   12/15/2016 3:21  Kitchen      3  Vocal1, Withdrawn   \n",
       "2    12/15/2016 19:14   12/16/2016 2:20    Other      3          Withdrawn   \n",
       "3     12/19/2016 1:57   12/19/2016 1:55    Other      4          Withdrawn   \n",
       "4    12/28/2016 20:36  12/28/2016 19:00    Other      4  Vocal2, Withdrawn   \n",
       "..                ...               ...      ...    ...                ...   \n",
       "307   7/29/2017 10:42   7/29/2017 10:42  Kitchen      1        Repetition;   \n",
       "308  08/03/2017 12:45  08/03/2017 12:44  Kitchen      1        Repetition;   \n",
       "309  08/04/2017 22:13  08/04/2017 22:13  Kitchen      1        Repetition;   \n",
       "310  08/07/2017 11:44  08/07/2017 11:44  Kitchen      1        Repetition;   \n",
       "311  08/08/2017 19:15  08/08/2017 19:15  Kitchen      1        Repetition;   \n",
       "\n",
       "    Behaviour  \n",
       "0      Normal  \n",
       "1      Normal  \n",
       "2      Normal  \n",
       "3      Normal  \n",
       "4      Normal  \n",
       "..        ...  \n",
       "307    Normal  \n",
       "308    Normal  \n",
       "309    Normal  \n",
       "310    Normal  \n",
       "311    Normal  \n",
       "\n",
       "[312 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b321da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(df.Observation, df.Behaviour, test_size = 0.2, stratify = df.Behaviour\n",
    "                                                 ,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7db9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_length'] = df['Observation'].apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d7289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "num_words = 10000 # this means 15000 unique words can be taken \n",
    "tokenizer=Tokenizer(num_words,lower=True)\n",
    "df_total = pd.concat([X_train, X_test], axis = 0)\n",
    "tokenizer.fit_on_texts(df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08ca3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a045d8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word_length.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0583f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_ =tokenizer.texts_to_sequences(X_train)\n",
    "X_train_pad=pad_sequences(X_train_,maxlen=171,padding='post')\n",
    "X_test_ = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_pad = pad_sequences(X_test_, maxlen = 171, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "908afb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 171) (63, 171)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pad.shape,X_test_pad.shape) # this is our 2D matrix we can take this as Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cba94bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding,Bidirectional\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8faf7109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dc85207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "glove_gensim  = api.load('glove-wiki-gigaword-100') # this would download vector with 100 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29355e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_gensim['cat'].shape[0] # this is the diemnsion of the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "671dedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM,CuDNNGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d8b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 100\n",
    "gensim_weight_matrix = np.zeros((num_words ,vector_size))\n",
    "gensim_weight_matrix.shape\n",
    "\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index < num_words: # since index starts with zero \n",
    "        if word in glove_gensim.key_to_index:\n",
    "            gensim_weight_matrix[index] = glove_gensim[word]\n",
    "        else:\n",
    "            gensim_weight_matrix[index] = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97cef1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_weight_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a92f14cc",
   "metadata": {},
   "outputs": [],
   "source": [
    " #designing our architecture \n",
    "EMBEDDING_DIM = 100 # this means the embedding layer will create  a vector in 100 dimension\n",
    "model_gensim = Sequential()\n",
    "model_gensim.add(Embedding(input_dim = num_words,# the whole vocabulary size \n",
    "                          output_dim = EMBEDDING_DIM, # vector space dimension\n",
    "                          input_length= X_train_pad.shape[1], # max_len of text sequence\n",
    "                          weights = [gensim_weight_matrix],trainable = False))\n",
    "model_gensim.add(Dropout(0.2))\n",
    "model_gensim.add(Bidirectional(CuDNNLSTM(100,return_sequences=True)))\n",
    "model_gensim.add(Dropout(0.2))\n",
    "model_gensim.add(Bidirectional(CuDNNLSTM(200,return_sequences=True)))\n",
    "model_gensim.add(Dropout(0.2))\n",
    "model_gensim.add(Bidirectional(CuDNNLSTM(100,return_sequences=False)))\n",
    "model_gensim.add(Dense(1, activation = 'sigmoid'))\n",
    "model_gensim.compile(loss = 'binary_crossentropy', optimizer = 'adam',metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "950b6a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 171, 100)          1000000   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 171, 100)          0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 171, 200)         161600    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 171, 200)          0         \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 171, 400)         643200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 171, 400)          0         \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 200)              401600    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,206,601\n",
      "Trainable params: 1,206,601\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gensim.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a394d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)\n",
    "mc = ModelCheckpoint('./model_gensim.h5', monitor = 'val_accuracy', mode = 'max', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2269b369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'CudnnRNNV2' used by {{node sequential_1/bidirectional_3/forward_cu_dnnlstm/CudnnRNNV2}} with these attrs: [seed=0, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", seed2=0, is_training=true]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[sequential_1/bidirectional_3/forward_cu_dnnlstm/CudnnRNNV2]] [Op:__inference_train_function_21924]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5776/1898723421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory_gensim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_gensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNNV2' used by {{node sequential_1/bidirectional_3/forward_cu_dnnlstm/CudnnRNNV2}} with these attrs: [seed=0, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", seed2=0, is_training=true]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[sequential_1/bidirectional_3/forward_cu_dnnlstm/CudnnRNNV2]] [Op:__inference_train_function_21924]"
     ]
    }
   ],
   "source": [
    "history_gensim = model_gensim.fit(X_train_pad,y_train, epochs = 25, batch_size = 120, validation_data=(X_test_pad, y_test),verbose = 1, callbacks= [es, mc]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96b721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
